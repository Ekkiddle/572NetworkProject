{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from nilearn import datasets, input_data\n",
    "from nilearn.image import resample_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1.5 # repition time (time that each image takes up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">get_dataset_dir</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in C:\\Users\\ekkid\\nilearn_data\\schaefer_2018\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mget_dataset_dir\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in C:\\Users\\ekkid\\nilearn_data\\schaefer_2018\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Schaefer 600 parcellation atlas\n",
    "schaefer = datasets.fetch_atlas_schaefer_2018(n_rois=600, resolution_mm=2, yeo_networks=7)\n",
    "atlas_img = nib.load(schaefer.maps)\n",
    "atlas_labels = schaefer.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all fMRI images in the data directory (taking from subject 1 and averaging all 6 test trials)\n",
    "directory = \"data\"\n",
    "\n",
    "fmri_images = []\n",
    "timestamps_list = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".nii\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        img = nib.load(filepath)\n",
    "        # Append the image to a list of the images that I would like to use.\n",
    "        fmri_images.append(img)\n",
    "    if filename.endswith(\".tsv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        stamp = pd.read_csv(filepath, sep=\"\\t\")\n",
    "        timestamps_list.append(stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n"
     ]
    }
   ],
   "source": [
    "reference_img = fmri_images[0]\n",
    "\n",
    "# Resample all fMRI images to match the first one. Allows for all the images to be the same shape.\n",
    "resampled_fmri_images = []\n",
    "for img in fmri_images:\n",
    "    resampled_fmri_images.append(resample_to_img(img, reference_img, interpolation=\"linear\", copy_header=True, force_resample=True))\n",
    "    print(f\"Done resampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, input_data\n",
    "\n",
    "# Resample atlas to match the first fMRI image\n",
    "reference_img = fmri_images[0]\n",
    "resampled_atlas = image.resample_to_img(\n",
    "    atlas_img, reference_img, interpolation=\"nearest\", copy_header=True, force_resample=True\n",
    ")\n",
    "\n",
    "# Save the resampled atlas for consistency\n",
    "resampled_atlas.to_filename(\"resampled_atlas.nii.gz\")\n",
    "\n",
    "# Use this resampled atlas consistently\n",
    "masker = input_data.NiftiLabelsMasker(resampled_atlas, standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n"
     ]
    }
   ],
   "source": [
    "# Now process all fMRI images with the same masker\n",
    "fmri_series = []\n",
    "for img in resampled_fmri_images:\n",
    "    series = masker.fit_transform(img)\n",
    "    fmri_series.append(series)\n",
    "    print(f\"Done Series: {series.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_indices_list = []\n",
    "genres = []\n",
    "# Loop through all stamps\n",
    "for stamps in timestamps_list:\n",
    "    genre_fmri_indices = {}\n",
    "    \n",
    "    # Loop through all rows\n",
    "    for _, row in stamps.iterrows():\n",
    "        genre = row['genre']\n",
    "        onset = row['onset']\n",
    "        duration = row ['duration']\n",
    "\n",
    "        # Compute fMRI indices\n",
    "        start_index = int(onset / TR)\n",
    "        end_index = int((onset + duration) / TR)\n",
    "        \n",
    "        # Create list of fMRI indices in this range\n",
    "        indices = list(range(start_index, end_index))\n",
    "        \n",
    "        # Store in dictionary\n",
    "        if genre in genre_fmri_indices:\n",
    "            genre_fmri_indices[genre].extend(indices)\n",
    "        else:\n",
    "            genre_fmri_indices[genre] = indices\n",
    "\n",
    "        if genre not in genres:\n",
    "            genres.append(genre)\n",
    "\n",
    "    # Remove duplicates and sort indices for each genre\n",
    "    for genre in genre_fmri_indices:\n",
    "        genre_fmri_indices[genre] = sorted(set(genre_fmri_indices[genre]))\n",
    "\n",
    "    genre_indices_list.append(genre_fmri_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.05209751 -1.48261402 -2.14670053 ... -0.99089043 -1.35943729\n",
      "  -1.32067788]\n",
      " [-2.14916395 -1.81790213 -2.54322959 ... -0.95848848 -1.6221799\n",
      "  -1.54232861]\n",
      " [-1.92992322 -2.60770969 -2.21530635 ... -1.39539221 -1.62791842\n",
      "  -1.40026854]\n",
      " ...\n",
      " [ 1.55282058  2.14794008  1.25904346 ...  2.49702287  1.88324093\n",
      "   1.47286172]\n",
      " [ 1.68819591  0.05218932  1.56808436 ...  2.87957494  2.24558799\n",
      "   1.88377163]\n",
      " [ 1.81502939  1.2789117   1.63731959 ...  2.30052071  2.27387073\n",
      "   1.93652358]]\n",
      "(574, 574)\n"
     ]
    }
   ],
   "source": [
    "genre_fmri_indices = {}\n",
    "# Loop through all rows\n",
    "for _, row in timestamps_list[0].iterrows():\n",
    "    genre = row['genre']\n",
    "    onset = row['onset']\n",
    "    duration = row['duration']\n",
    "    \n",
    "    # Compute fMRI indices\n",
    "    start_index = int(onset / TR)\n",
    "    end_index = int((onset + duration) / TR)\n",
    "    \n",
    "    # Create list of fMRI indices in this range\n",
    "    indices = list(range(start_index, end_index))\n",
    "    \n",
    "    # Store in dictionary\n",
    "    if genre in genre_fmri_indices:\n",
    "        genre_fmri_indices[genre].extend(indices)\n",
    "    else:\n",
    "        genre_fmri_indices[genre] = indices\n",
    "\n",
    "# Remove duplicates and sort indices for each genre\n",
    "for genre in genre_fmri_indices:\n",
    "    genre_fmri_indices[genre] = sorted(set(genre_fmri_indices[genre]))\n",
    "\n",
    "pop_time_series = fmri_series[0][genre_fmri_indices[\"'pop'\"]]\n",
    "print(pop_time_series)\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = np.corrcoef(pop_time_series.T)\n",
    "print(correlation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels after resampling: 574\n",
      "Remaining labels: [b'7Networks_LH_Vis_1', b'7Networks_LH_Vis_2', b'7Networks_LH_Vis_3', b'7Networks_LH_Vis_4', b'7Networks_LH_Vis_5', b'7Networks_LH_Vis_6', b'7Networks_LH_Vis_7', b'7Networks_LH_Vis_9', b'7Networks_LH_Vis_10', b'7Networks_LH_Vis_11']\n"
     ]
    }
   ],
   "source": [
    "# Get unique labels (nonzero ones)\n",
    "masked_atlas_labels = np.unique(resampled_atlas.get_fdata().astype(int))\n",
    "masked_atlas_labels = masked_atlas_labels[masked_atlas_labels > 0]  # Exclude background (zero)\n",
    "\n",
    "# Get the corresponding label names\n",
    "remaining_label_names = [atlas_labels[label - 1] for label in masked_atlas_labels]  # -1 to index correctly\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of labels after resampling: {len(remaining_label_names)}\")\n",
    "print(\"Remaining labels:\", remaining_label_names[:10])  # Print first 10 for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "\n",
    "resampled_data = resampled_atlas.get_fdata()  # Get voxel data\n",
    "affine = resampled_atlas.affine  # Get new affine matrix\n",
    "\n",
    "# Compute center of mass only for kept labels\n",
    "centers_of_mass = []\n",
    "for label in masked_atlas_labels:\n",
    "    mask = resampled_data == label\n",
    "    if np.any(mask):  \n",
    "        com_voxel = scipy.ndimage.center_of_mass(mask)  \n",
    "        com_mni = tuple(nib.affines.apply_affine(affine, com_voxel))  # Convert to tuple\n",
    "        centers_of_mass.append(com_mni)\n",
    "\n",
    "# Convert to NumPy array for easy access\n",
    "centers_of_mass = np.array(centers_of_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-26.04532855, -44.8448842 , -14.95132551],\n",
       "       [-33.51755533, -58.54877338, -17.15993676],\n",
       "       [-31.59200801, -41.29417978, -10.28358888],\n",
       "       ...,\n",
       "       [  9.98199591, -43.69421859,  38.11650459],\n",
       "       [  8.2240946 , -49.76169968,  44.2513828 ],\n",
       "       [  6.62673836, -61.43118558,  44.78670274]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node list and edge list for 'pop' have been saved.\n",
      "Node list and edge list for 'rock' have been saved.\n",
      "Node list and edge list for 'country' have been saved.\n",
      "Node list and edge list for 'blues' have been saved.\n",
      "Node list and edge list for 'disco' have been saved.\n",
      "Node list and edge list for 'metal' have been saved.\n",
      "Node list and edge list for 'reggae' have been saved.\n",
      "Node list and edge list for 'classical' have been saved.\n",
      "Node list and edge list for 'hiphop' have been saved.\n",
      "Node list and edge list for 'jazz' have been saved.\n"
     ]
    }
   ],
   "source": [
    "brain_regions = []\n",
    "# Do this for each genre.\n",
    "for genre in genres:\n",
    "    genre_series_list = []\n",
    "    for i in range(len(fmri_series)):\n",
    "        series = fmri_series[i]\n",
    "        indices = genre_indices_list[i]\n",
    "        genre_series_list.append(series[indices[genre]])  # Collect relevant time series\n",
    "\n",
    "    genre_series = np.vstack(genre_series_list)  # Final shape: (250, 574)\n",
    "    # Create a correlation matrix from the total time series\n",
    "    correlation_matrix = np.corrcoef(genre_series.T)\n",
    "    #average_matrix = matrices[0]\n",
    "\n",
    "    # Create the node list for this genre\n",
    "    parsed_labels = []\n",
    "    for label in remaining_label_names:\n",
    "        label = label.decode(\"utf-8\")  # Convert bytes to string\n",
    "        parts = label.split(\"_\")\n",
    "        \n",
    "        network = parts[0]  # \"7Networks\"\n",
    "        hemisphere = parts[1]  # \"LH\" or \"RH\"\n",
    "        region = \"_\".join(parts[2:-1])  # Join everything in between as the region\n",
    "        parcel_id = parts[-1]  # Last part is the parcel number\n",
    "\n",
    "        brain_region = {\"hemisphere\": hemisphere, \"Region\":region}\n",
    "        if not brain_region in brain_regions:\n",
    "            brain_regions.append(brain_region)\n",
    "\n",
    "        parsed_labels.append([label, network, hemisphere, region, parcel_id])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    node_list = pd.DataFrame(parsed_labels, columns=[\"Label\", \"Network\", \"Hemisphere\", \"Region\", \"Parcel ID\"])\n",
    "    node_list.insert(0, \"Node\", range(1, len(node_list) + 1))  # Add Node index\n",
    "    # Add the coordinates as separate columns\n",
    "    node_list[\"X\"] = centers_of_mass[:, 0]  # First column of com_list\n",
    "    node_list[\"Y\"] = centers_of_mass[:, 1]  # Second column of com_list\n",
    "    node_list[\"Z\"] = centers_of_mass[:, 2]  # Third column of com_list\n",
    "\n",
    "    # Save to CSV inside the 'networks' folder\n",
    "    node_list.to_csv(f\"networks/{genre}_node_list.csv\", index=False)\n",
    "\n",
    "    # Create edge list for correlations greater than 0.7\n",
    "    edges = []\n",
    "    n_nodes = correlation_matrix.shape[0]\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(i + 1, n_nodes):  # Avoid duplicates\n",
    "            # Add all edges to the graph\n",
    "            edges.append((i + 1, j + 1, correlation_matrix[i, j]))\n",
    "\n",
    "    # Sort edges by correlation value (descending order)\n",
    "    edges.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Select top k edges\n",
    "    k = 6000  # Define fixed number of edges. FIXED DENSITY\n",
    "    edges = edges[:k]  # Take the top-k strongest edges\n",
    "\n",
    "    edge_list = pd.DataFrame(edges, columns=[\"Node1\", \"Node2\", \"Correlation\"])\n",
    "    edge_list.to_csv(f\"networks/{genre}_edge_list.csv\", index=False)\n",
    "\n",
    "    print(f\"Node list and edge list for {genre} have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hemisphere': 'LH', 'Region': 'Vis'},\n",
       " {'hemisphere': 'LH', 'Region': 'SomMot'},\n",
       " {'hemisphere': 'LH', 'Region': 'DorsAttn_Post'},\n",
       " {'hemisphere': 'LH', 'Region': 'DorsAttn_FEF'},\n",
       " {'hemisphere': 'LH', 'Region': 'DorsAttn_PrCv'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_ParOper'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_TempOcc'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_FrOperIns'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_PFCl'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_Med'},\n",
       " {'hemisphere': 'LH', 'Region': 'Limbic_OFC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Limbic_TempPole'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_Par'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_Temp'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCd'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_OFC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCl'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCv'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_pCun'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_Cing'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCmp'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_Temp'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_Par'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_PFC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_pCunPCC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_PHC'},\n",
       " {'hemisphere': 'RH', 'Region': 'Vis'},\n",
       " {'hemisphere': 'RH', 'Region': 'SomMot'},\n",
       " {'hemisphere': 'RH', 'Region': 'DorsAttn_Post'},\n",
       " {'hemisphere': 'RH', 'Region': 'DorsAttn_FEF'},\n",
       " {'hemisphere': 'RH', 'Region': 'DorsAttn_PrCv'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_TempOccPar'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_PrC'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_FrOperIns'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_PFCl'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_Med'},\n",
       " {'hemisphere': 'RH', 'Region': 'Limbic_OFC'},\n",
       " {'hemisphere': 'RH', 'Region': 'Limbic_TempPole'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_Par'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_Temp'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_PFCv'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_PFCl'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_pCun'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_Cing'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_PFCmp'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_Par'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_Temp'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_PFCv'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_PFCdPFCm'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_pCunPCC'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_regions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
