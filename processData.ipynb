{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from nilearn import datasets, input_data\n",
    "from nilearn.image import resample_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1.5 # repition time (time that each image takes up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">get_dataset_dir</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in C:\\Users\\ekkid\\nilearn_data\\schaefer_2018\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mget_dataset_dir\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in C:\\Users\\ekkid\\nilearn_data\\schaefer_2018\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Schaefer 600 parcellation atlas\n",
    "schaefer = datasets.fetch_atlas_schaefer_2018(n_rois=600, resolution_mm=2, yeo_networks=7)\n",
    "atlas_img = nib.load(schaefer.maps)\n",
    "atlas_labels = schaefer.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all fMRI images in the data directory (taking from subject 1 and averaging all 6 test trials)\n",
    "directory = \"data\"\n",
    "\n",
    "fmri_images = []\n",
    "timestamps_list = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".nii\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        img = nib.load(filepath)\n",
    "        # Append the image to a list of the images that I would like to use.\n",
    "        fmri_images.append(img)\n",
    "    if filename.endswith(\".tsv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        stamp = pd.read_csv(filepath, sep=\"\\t\")\n",
    "        timestamps_list.append(stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n",
      "Done resampling\n"
     ]
    }
   ],
   "source": [
    "reference_img = fmri_images[0]\n",
    "\n",
    "# Resample all fMRI images to match the first one. Allows for all the images to be the same shape.\n",
    "resampled_fmri_images = []\n",
    "for img in fmri_images:\n",
    "    resampled_fmri_images.append(resample_to_img(img, reference_img, interpolation=\"linear\", copy_header=True, force_resample=True))\n",
    "    print(f\"Done resampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, input_data\n",
    "\n",
    "# Resample atlas to match the first fMRI image\n",
    "reference_img = fmri_images[0]\n",
    "resampled_atlas = image.resample_to_img(\n",
    "    atlas_img, reference_img, interpolation=\"nearest\", copy_header=True, force_resample=True\n",
    ")\n",
    "\n",
    "# Save the resampled atlas for consistency\n",
    "resampled_atlas.to_filename(\"resampled_atlas.nii.gz\")\n",
    "\n",
    "# Use this resampled atlas consistently\n",
    "masker = input_data.NiftiLabelsMasker(resampled_atlas, standardize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n",
      "Done Series: (410, 574)\n"
     ]
    }
   ],
   "source": [
    "# Now process all fMRI images with the same masker\n",
    "fmri_series = []\n",
    "for img in resampled_fmri_images:\n",
    "    series = masker.fit_transform(img)\n",
    "    fmri_series.append(series)\n",
    "    print(f\"Done Series: {series.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_indices_list = []\n",
    "genres = []\n",
    "# Loop through all stamps\n",
    "for stamps in timestamps_list:\n",
    "    genre_fmri_indices = {}\n",
    "    \n",
    "    # Loop through all rows\n",
    "    for _, row in stamps.iterrows():\n",
    "        genre = row['genre']\n",
    "        onset = row['onset']\n",
    "        duration = row ['duration']\n",
    "\n",
    "        # Compute fMRI indices\n",
    "        start_index = int(onset / TR)\n",
    "        end_index = int((onset + duration) / TR)\n",
    "        \n",
    "        # Create list of fMRI indices in this range\n",
    "        indices = list(range(start_index, end_index))\n",
    "        \n",
    "        # Store in dictionary\n",
    "        if genre in genre_fmri_indices:\n",
    "            genre_fmri_indices[genre].extend(indices)\n",
    "        else:\n",
    "            genre_fmri_indices[genre] = indices\n",
    "\n",
    "        if genre not in genres:\n",
    "            genres.append(genre)\n",
    "\n",
    "    # Remove duplicates and sort indices for each genre\n",
    "    for genre in genre_fmri_indices:\n",
    "        genre_fmri_indices[genre] = sorted(set(genre_fmri_indices[genre]))\n",
    "\n",
    "    genre_indices_list.append(genre_fmri_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.05209751 -1.48261402 -2.14670053 ... -0.99089043 -1.35943729\n",
      "  -1.32067788]\n",
      " [-2.14916395 -1.81790213 -2.54322959 ... -0.95848848 -1.6221799\n",
      "  -1.54232861]\n",
      " [-1.92992322 -2.60770969 -2.21530635 ... -1.39539221 -1.62791842\n",
      "  -1.40026854]\n",
      " ...\n",
      " [ 1.55282058  2.14794008  1.25904346 ...  2.49702287  1.88324093\n",
      "   1.47286172]\n",
      " [ 1.68819591  0.05218932  1.56808436 ...  2.87957494  2.24558799\n",
      "   1.88377163]\n",
      " [ 1.81502939  1.2789117   1.63731959 ...  2.30052071  2.27387073\n",
      "   1.93652358]]\n",
      "(574, 574)\n"
     ]
    }
   ],
   "source": [
    "genre_fmri_indices = {}\n",
    "# Loop through all rows\n",
    "for _, row in timestamps_list[0].iterrows():\n",
    "    genre = row['genre']\n",
    "    onset = row['onset']\n",
    "    duration = row['duration']\n",
    "    \n",
    "    # Compute fMRI indices\n",
    "    start_index = int(onset / TR)\n",
    "    end_index = int((onset + duration) / TR)\n",
    "    \n",
    "    # Create list of fMRI indices in this range\n",
    "    indices = list(range(start_index, end_index))\n",
    "    \n",
    "    # Store in dictionary\n",
    "    if genre in genre_fmri_indices:\n",
    "        genre_fmri_indices[genre].extend(indices)\n",
    "    else:\n",
    "        genre_fmri_indices[genre] = indices\n",
    "\n",
    "# Remove duplicates and sort indices for each genre\n",
    "for genre in genre_fmri_indices:\n",
    "    genre_fmri_indices[genre] = sorted(set(genre_fmri_indices[genre]))\n",
    "\n",
    "pop_time_series = fmri_series[0][genre_fmri_indices[\"'pop'\"]]\n",
    "print(pop_time_series)\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = np.corrcoef(pop_time_series.T)\n",
    "print(correlation_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels after resampling: 574\n",
      "Remaining labels: [b'7Networks_LH_Vis_1', b'7Networks_LH_Vis_2', b'7Networks_LH_Vis_3', b'7Networks_LH_Vis_4', b'7Networks_LH_Vis_5', b'7Networks_LH_Vis_6', b'7Networks_LH_Vis_7', b'7Networks_LH_Vis_9', b'7Networks_LH_Vis_10', b'7Networks_LH_Vis_11']\n"
     ]
    }
   ],
   "source": [
    "# Get unique labels (nonzero ones)\n",
    "masked_atlas_labels = np.unique(resampled_atlas.get_fdata().astype(int))\n",
    "masked_atlas_labels = masked_atlas_labels[masked_atlas_labels > 0]  # Exclude background (zero)\n",
    "\n",
    "# Get the corresponding label names\n",
    "remaining_label_names = [atlas_labels[label - 1] for label in masked_atlas_labels]  # -1 to index correctly\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of labels after resampling: {len(remaining_label_names)}\")\n",
    "print(\"Remaining labels:\", remaining_label_names[:10])  # Print first 10 for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16704\\1156052603.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m# Add all edges to the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0medges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorrelation_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# Sort edges by correlation value (descending order)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0medge_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# Select top k edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6000\u001b[0m  \u001b[1;31m# Define fixed number of edges. FIXED DENSITY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "brain_regions = []\n",
    "# Do this for each genre.\n",
    "for genre in genres:\n",
    "    genre_series_list = []\n",
    "    for i in range(len(fmri_series)):\n",
    "        series = fmri_series[i]\n",
    "        indices = genre_indices_list[i]\n",
    "        genre_series_list.append(series[indices[genre]])  # Collect relevant time series\n",
    "\n",
    "    genre_series = np.vstack(genre_series_list)  # Final shape: (250, 574)\n",
    "    # Create a correlation matrix from the total time series\n",
    "    correlation_matrix = np.corrcoef(genre_series.T)\n",
    "    #average_matrix = matrices[0]\n",
    "\n",
    "    # Create the node list for this genre\n",
    "    parsed_labels = []\n",
    "    for label in remaining_label_names:\n",
    "        label = label.decode(\"utf-8\")  # Convert bytes to string\n",
    "        parts = label.split(\"_\")\n",
    "        \n",
    "        network = parts[0]  # \"7Networks\"\n",
    "        hemisphere = parts[1]  # \"LH\" or \"RH\"\n",
    "        region = \"_\".join(parts[2:-1])  # Join everything in between as the region\n",
    "        parcel_id = parts[-1]  # Last part is the parcel number\n",
    "\n",
    "        brain_region = {\"hemisphere\": hemisphere, \"Region\":region}\n",
    "        if not brain_region in brain_regions:\n",
    "            brain_regions.append(brain_region)\n",
    "\n",
    "        parsed_labels.append([label, network, hemisphere, region, parcel_id])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    node_list = pd.DataFrame(parsed_labels, columns=[\"Label\", \"Network\", \"Hemisphere\", \"Region\", \"Parcel ID\"])\n",
    "    node_list.insert(0, \"Node\", range(1, len(node_list) + 1))  # Add Node index\n",
    "\n",
    "    # Save to CSV inside the 'networks' folder\n",
    "    node_list.to_csv(f\"networks/{genre}_node_list.csv\", index=False)\n",
    "\n",
    "    # Create edge list for correlations greater than 0.7\n",
    "    edges = []\n",
    "    n_nodes = correlation_matrix.shape[0]\n",
    "    for i in range(n_nodes):\n",
    "        for j in range(i + 1, n_nodes):  # Avoid duplicates\n",
    "            # Add all edges to the graph\n",
    "            edges.append((i + 1, j + 1, correlation_matrix[i, j]))\n",
    "\n",
    "    # Sort edges by correlation value (descending order)\n",
    "    edges.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Select top k edges\n",
    "    k = 6000  # Define fixed number of edges. FIXED DENSITY\n",
    "    edges = edges[:k]  # Take the top-k strongest edges\n",
    "\n",
    "    edge_list = pd.DataFrame(edges, columns=[\"Node1\", \"Node2\", \"Correlation\"])\n",
    "    edge_list.to_csv(f\"networks/{genre}_edge_list.csv\", index=False)\n",
    "\n",
    "    print(f\"Node list and edge list for {genre} have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'hemisphere': 'LH', 'Region': 'Vis'},\n",
       " {'hemisphere': 'LH', 'Region': 'SomMot'},\n",
       " {'hemisphere': 'LH', 'Region': 'DorsAttn_Post'},\n",
       " {'hemisphere': 'LH', 'Region': 'DorsAttn_FEF'},\n",
       " {'hemisphere': 'LH', 'Region': 'DorsAttn_PrCv'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_ParOper'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_TempOcc'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_FrOperIns'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_PFCl'},\n",
       " {'hemisphere': 'LH', 'Region': 'SalVentAttn_Med'},\n",
       " {'hemisphere': 'LH', 'Region': 'Limbic_OFC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Limbic_TempPole'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_Par'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_Temp'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCd'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_OFC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCl'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCv'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_pCun'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_Cing'},\n",
       " {'hemisphere': 'LH', 'Region': 'Cont_PFCmp'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_Temp'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_Par'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_PFC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_pCunPCC'},\n",
       " {'hemisphere': 'LH', 'Region': 'Default_PHC'},\n",
       " {'hemisphere': 'RH', 'Region': 'Vis'},\n",
       " {'hemisphere': 'RH', 'Region': 'SomMot'},\n",
       " {'hemisphere': 'RH', 'Region': 'DorsAttn_Post'},\n",
       " {'hemisphere': 'RH', 'Region': 'DorsAttn_FEF'},\n",
       " {'hemisphere': 'RH', 'Region': 'DorsAttn_PrCv'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_TempOccPar'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_PrC'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_FrOperIns'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_PFCl'},\n",
       " {'hemisphere': 'RH', 'Region': 'SalVentAttn_Med'},\n",
       " {'hemisphere': 'RH', 'Region': 'Limbic_OFC'},\n",
       " {'hemisphere': 'RH', 'Region': 'Limbic_TempPole'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_Par'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_Temp'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_PFCv'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_PFCl'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_pCun'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_Cing'},\n",
       " {'hemisphere': 'RH', 'Region': 'Cont_PFCmp'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_Par'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_Temp'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_PFCv'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_PFCdPFCm'},\n",
       " {'hemisphere': 'RH', 'Region': 'Default_pCunPCC'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_regions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
