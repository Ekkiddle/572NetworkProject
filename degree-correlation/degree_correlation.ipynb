{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:05.893950Z",
     "start_time": "2025-04-07T22:53:05.885184Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import statsmodels\n",
    "from sklearn import ensemble\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.graphics.api import abline_plot, interaction_plot\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 440
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:05.908395Z",
     "start_time": "2025-04-07T22:53:05.902410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for each node in a network, find the degree of its neighbors and take the average\n",
    "# stores the degree and average neighbor degree in a dataframe\n",
    "def get_avg_nn_degree(network):\n",
    "    degrees = network.degree\n",
    "    degree = []\n",
    "    k_nearest_neighbors = []\n",
    "    for i in network.nodes:\n",
    "        k_i = degrees[i]\n",
    "        if k_i > 0:\n",
    "            network.nodes[i]['degree'] = k_i\n",
    "            k_nn = sum([degrees[j] for j in network.neighbors(i)]) / k_i\n",
    "            network.nodes[i]['avg_knn'] = k_nn\n",
    "            degree.append(k_i)\n",
    "            k_nearest_neighbors.append(k_nn)\n",
    "        else:\n",
    "            network.nodes[i]['degree'] = 0\n",
    "            network.nodes[i]['avg_knn'] = 0\n",
    "            degree.append(0)\n",
    "            k_nearest_neighbors.append(0)\n",
    "    return pd.DataFrame({'degree': degree, 'average_nearest_neighbor_degree': k_nearest_neighbors})"
   ],
   "id": "2653a4d7cf6622f2",
   "outputs": [],
   "execution_count": 441
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:05.934715Z",
     "start_time": "2025-04-07T22:53:05.930237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for each network in the ensemble dataframe, gets the average nearest neighbor\n",
    "# degree and puts it all in a dataframe\n",
    "def get_avg_nn_degree_null(ensemble):\n",
    "    network_nos = ensemble['network_no'].unique()\n",
    "    null_nn = pd.DataFrame(columns=['degree', 'average_nearest_neighbor_degree'])\n",
    "    for i in network_nos:\n",
    "        null_edge_list = ensemble.loc[ensemble['network_no'] == i]\n",
    "        null_network = nx.from_pandas_edgelist(null_edge_list, source='source', target='target')\n",
    "        new_rows = get_avg_nn_degree(null_network)\n",
    "        null_nn = pd.concat([null_nn, new_rows])\n",
    "    return null_nn\n"
   ],
   "id": "a042a6d21eadf943",
   "outputs": [],
   "execution_count": 442
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Finding line of best fit and $\\mu$ for $k_{nn}(k)$:\n",
    "For a non-neutral network, the line that best fits $k_{nn}(k)$ is given by: :\n",
    "\\begin{align}\n",
    "k_{nn}(k) = ak^{\\mu}\n",
    "\\end{align}\n",
    "We need to find the values $a, \\mu$ that best fit the data. Taking the logarithm of both sides gives us:\n",
    "\\begin{align}\n",
    "log(k_{nn}(k)) &= log(ak^{\\mu}) \\\\\n",
    "&= log(a) + \\mu log(k)\n",
    "\\end{align}\n",
    "let:\n",
    "- $K_{NN}(K) = log(k_{nn}(k))$\n",
    "- $K = log(k)$\n",
    "- $A = log(a)$\n",
    "\n",
    "Substituting in these variables gives us a linear equation of the form:\n",
    "\\begin{align}\n",
    "K_{nn}(K) = A + \\mu K\n",
    "\\end{align}\n",
    "We can use linear regression to find the values for $\\mu$ and $A$, and find $a$ by using $a=10^A$.\n"
   ],
   "id": "c5929b5e14b3036e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:05.959640Z",
     "start_time": "2025-04-07T22:53:05.955251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_line(nn_df):\n",
    "    # transform k and k_nn\n",
    "    log_k = np.log10(nn_df['degree'].values)\n",
    "    log_knn = np.log10(nn_df['average_nearest_neighbor_degree'].values)\n",
    "    # add constant term for intercept (A)\n",
    "    log_k = sm.add_constant(log_k)\n",
    "    # Fit the model\n",
    "    model = sm.OLS(log_knn, log_k).fit()\n",
    "\n",
    "    return model"
   ],
   "id": "9197cc082ab46e7e",
   "outputs": [],
   "execution_count": 443
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:05.988105Z",
     "start_time": "2025-04-07T22:53:05.980186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Draws the k nearest neighbours plot\n",
    "# def draw_knn(network, dp, rgg, genre, model):\n",
    "def draw_knn(network, genre, model, ax, palette, l, model_dp):\n",
    "    # Extract model parameters\n",
    "    A, mu = model.params\n",
    "    a = 10**A\n",
    "\n",
    "    A_dp, mu_dp = model_dp.params\n",
    "    a_dp = 10**A_dp\n",
    "\n",
    "    # Get coordinates for line of best fit\n",
    "    line_x = [k for k in network['degree'].unique()]\n",
    "    line_y = [a * (x**mu) for x in line_x]\n",
    "\n",
    "    # Group the network nearest neighbours by degree to make the scatterplot less cluttered\n",
    "    network_avgs = network.groupby('degree')['average_nearest_neighbor_degree'].mean()\n",
    "    max_degree = max(network_avgs.index)\n",
    "\n",
    "    x_null = [k for k in network['degree'].unique()]\n",
    "    y_null = [a_dp * (x**mu_dp) for x in x_null]\n",
    "\n",
    "    # fig, ax = plt.subplots(dpi=300)\n",
    "    ax.set(xscale='log',\n",
    "           yscale='log',\n",
    "           # xlim=(0,max_degree + 5),\n",
    "           # ylim=(0,120),\n",
    "           # xlabel='$ k $',\n",
    "           ylabel = '$ k_{nn}(k) $',\n",
    "           title=genre)\n",
    "           # title=f'Average nearest neighbor degree for {genre} genre')\n",
    "\n",
    "    sns.lineplot(x=line_x,\n",
    "                 y=line_y,\n",
    "                 ax=ax,\n",
    "                 label = fr'$ {a:.2f}k^{{{mu:.2f}}} $',\n",
    "                 alpha=.8,\n",
    "                 color = palette[l])\n",
    "\n",
    "    sns.lineplot(x = x_null,\n",
    "                 y = y_null,\n",
    "                 ax = ax,\n",
    "                 label = fr'null model: $ {a_dp: .2f}k^{{{mu_dp:.2f}}} $',\n",
    "                 color='grey')\n",
    "\n",
    "\n",
    "    sns.scatterplot(x=network_avgs.index,\n",
    "                              y=network_avgs.values,\n",
    "                              ax=ax,\n",
    "                              linewidth=.2,\n",
    "                              s = 15,\n",
    "                              alpha = 1,\n",
    "                              color= palette[9 - l])\n",
    "\n",
    "    # Draw nearest neighbor degree lines for null model ensembles\n",
    "    # sns.lineplot(data=dp, x='degree', y='average_nearest_neighbor_degree', ax=ax, err_style='band', errorbar='sd', label = 'degree preserving model')\n",
    "    # sns.lineplot(data=rgg, x='degree', y='average_nearest_neighbor_degree', ax=ax, err_style='band', errorbar='sd', label = 'random geometric model')\n",
    "    # Draw line of best fit for network k_nn\n",
    "\n",
    "\n",
    "    ax.legend(prop={'size': 6})\n",
    "    # fig.savefig(f'./plots/k_nearest_neighbors/{genre}_knn.png')\n",
    "\n",
    "    # plt.show()"
   ],
   "id": "a6bd214b5ffe5703",
   "outputs": [],
   "execution_count": 444
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:06.016825Z",
     "start_time": "2025-04-07T22:53:06.008668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_degree_probabilities_and_plot(network: nx.Graph, genre):\n",
    "    max_degree = max(k for node, k in network.degree())\n",
    "\n",
    "    degree_probability_matrix = get_degree_probabilities(network)\n",
    "\n",
    "    source_degree = []\n",
    "    target_degree = []\n",
    "    p = []\n",
    "    for j in range(max_degree):\n",
    "        for k in range(max_degree):\n",
    "            source_degree.append(j)\n",
    "            target_degree.append(k)\n",
    "            p.append(degree_probability_matrix[j, k])\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    heatmap_df = pd.DataFrame({'source degree $ j $': source_degree, 'target degree $ k $': target_degree, '$ e_{jk} $': p}) \\\n",
    "                   .pivot(index = 'source degree $ j $', columns = 'target degree $ k $', values = '$ e_{jk} $')\n",
    "\n",
    "    ax.set(title=f'Degree probability matrix for edges in the {genre} genre network\\n',\n",
    "           xlabel='target degree $ j $',\n",
    "           ylabel='source degree $ k $')\n",
    "\n",
    "    sns.heatmap(heatmap_df,\n",
    "                cbar_kws={'label': '$ e_{jk} $'},\n",
    "                ax=ax,\n",
    "                cmap='mako',\n",
    "                xticklabels=10,\n",
    "                yticklabels=10)\n",
    "\n",
    "\n",
    "    fig.savefig(f'./plots/heatmap/{genre}_heatmap.png')\n",
    "    # plt.show()\n",
    "\n",
    "    return degree_probability_matrix"
   ],
   "id": "39c2f8ba26e5ce5e",
   "outputs": [],
   "execution_count": 445
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:06.057755Z",
     "start_time": "2025-04-07T22:53:06.050706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_degree_probabilities(network: nx.Graph):\n",
    "    max_degree = max(k for node, k in network.degree())\n",
    "    degree_count_matrix = np.zeros(shape=(max_degree, max_degree))\n",
    "    degrees = network.degree\n",
    "\n",
    "    # j = row\n",
    "    # k = column\n",
    "    # For every edge in the network, count the number of times a node with degree j\n",
    "    # is connected to a node with degree k\n",
    "    for e in network.edges:\n",
    "        j = degrees[e[0]] - 1\n",
    "        k = degrees[e[1]] - 1\n",
    "        degree_count_matrix[j, k] += 1\n",
    "\n",
    "    # divide by the total number of edges to get a probability distribution\n",
    "    degree_probability_matrix = degree_count_matrix / network.number_of_edges()\n",
    "    return degree_probability_matrix"
   ],
   "id": "c5585c9b4fd17080",
   "outputs": [],
   "execution_count": 446
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:06.098699Z",
     "start_time": "2025-04-07T22:53:06.090910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# computes the assortativity coefficient r from the lecture on null models\n",
    "def compute_r(prob_matrix):\n",
    "    size = len(prob_matrix[0])\n",
    "    q_j = np.sum(prob_matrix, axis=1)\n",
    "    q_k = np.sum(prob_matrix, axis=0)\n",
    "    differences = np.sum([(j*k)*(prob_matrix[j][k] - (q_j[j] * q_k[k])) for j in range(size) for k in range(size)])\n",
    "    sigma = (np.sum([(k**2) * q_k[k] for k in range(size)])) - (np.sum([k * q_k[k] for k in range(size)])**2)\n",
    "    return differences/sigma"
   ],
   "id": "9f8723e4c9bc552",
   "outputs": [],
   "execution_count": 447
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:06.173560Z",
     "start_time": "2025-04-07T22:53:06.165995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_null_r(ensemble):\n",
    "    network_nos = ensemble['network_no'].unique()\n",
    "    null_rs = []\n",
    "    for i in network_nos:\n",
    "        null_edge_list = ensemble.loc[ensemble['network_no'] == i]\n",
    "        null_network = nx.from_pandas_edgelist(null_edge_list, source='source', target='target')\n",
    "        degree_probabilities = get_degree_probabilities(null_network)\n",
    "        null_rs.append(compute_r(degree_probabilities))\n",
    "    stats = np.array(statsmodels.stats.descriptivestats.Description(null_rs, stats = ['mean', 'ci'], alpha = 0.05).frame)\n",
    "    return stats"
   ],
   "id": "7c9b59ccc56b55d0",
   "outputs": [],
   "execution_count": 448
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:53:06.216092Z",
     "start_time": "2025-04-07T22:53:06.205047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def degree_correlation_metrics():\n",
    "    genres = ['blues', 'classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
    "    metrics_df = pd.DataFrame(columns = ['genre', 'a', 'mu', 'mu MoE', 'r', 'null_a', 'null_mu', 'null_mu_MoE', 'null_r', 'null_r_moe'])\n",
    "    fig, axs = plt.subplots(dpi=600, nrows=5, ncols=2, figsize=(8.5,11), sharex=True, sharey=True)\n",
    "    l = 0\n",
    "    palette = sns.color_palette('viridis', 10)\n",
    "    k_nn_df = pd.DataFrame(columns=['genre', 'k', 'k_nn'])\n",
    "    for genre in genres:\n",
    "        print(f\"calculating metrics for genre: {genre}\")\n",
    "        ensemble_dp = pd.read_csv(f\"../null-model-ensembles/networks/degree_preserving/{genre}_dp.csv\")\n",
    "        # ensemble_rgg = pd.read_csv(f\"../null-model-ensembles/networks/random_geometric/{genre}_rgg.csv\")\n",
    "\n",
    "        edge_list = pd.read_csv(f\"../networks/{genre}_edge_list.csv\").rename(columns={\"Node1\": \"source\", \"Node2\": \"target\"})\n",
    "        network = nx.from_pandas_edgelist(edge_list, source='source', target='target')\n",
    "\n",
    "        network_nn = get_avg_nn_degree(network).astype('float')\n",
    "        dp_nn = get_avg_nn_degree_null(ensemble_dp).astype('float')\n",
    "        # rgg_nn = get_avg_nn_degree_null(ensemble_rgg)\n",
    "\n",
    "        new_rows = pd.DataFrame({'genre': [genre for i in range(network_nn.shape[0])],'k': network_nn['degree'].values, 'k_nn': network_nn['average_nearest_neighbor_degree'].values})\n",
    "        k_nn_df = pd.concat([k_nn_df, new_rows])\n",
    "\n",
    "        model = find_line(network_nn)\n",
    "        A, mu = model.params\n",
    "        a = 10**A\n",
    "\n",
    "        model_dp = find_line(dp_nn)\n",
    "        A_dp, mu_dp = model_dp.params\n",
    "        a_dp = 10**A_dp\n",
    "\n",
    "        # get confidence interval for mu\n",
    "        cis = model.conf_int()\n",
    "        mu_ci = cis[1]\n",
    "        mu_moe = mu_ci[1] - mu\n",
    "\n",
    "        null_cis = model_dp.conf_int()\n",
    "        null_mu_ci = null_cis[1]\n",
    "        mu_moe_null = null_mu_ci[1] - mu_dp\n",
    "\n",
    "        i = int (l / 2)\n",
    "        j = l % 2\n",
    "        current_ax = axs[i][j]\n",
    "\n",
    "        # draw graphs, and add degree correlation metrics to dataframe\n",
    "        # draw_knn(network_nn, dp_nn, rgg_nn, genre, model)\n",
    "        scatter = draw_knn(network_nn, genre, model, current_ax, palette, l, model_dp)\n",
    "        degree_probability_matrix = get_degree_probabilities_and_plot(network, genre)\n",
    "\n",
    "        r = compute_r(degree_probability_matrix)\n",
    "\n",
    "        null_r_stats = get_null_r(ensemble_dp)\n",
    "        r_null = null_r_stats[0,0]\n",
    "        r_null_moe = (null_r_stats[1,0] - null_r_stats[2,0]) / 2\n",
    "\n",
    "        metrics_df.loc[metrics_df.shape[0],:] = [genre, a, mu, mu_moe, r, a_dp, mu_dp, mu_moe_null, r_null, r_null_moe]\n",
    "\n",
    "        l += 1\n",
    "\n",
    "    # metrics_df.to_csv('degree_correlation_metrics.csv', index=False)\n",
    "\n",
    "    axs[4][0].set(xlabel='degree $ k $')\n",
    "    axs[4][1].set(xlabel='degree $ k $')\n",
    "    fig.savefig(f'./plots/k_nearest_neighbors/all_genres_knn.png')\n",
    "\n",
    "    return metrics_df, k_nn_df\n"
   ],
   "id": "587f9ca8ed66396d",
   "outputs": [],
   "execution_count": 449
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:54:07.353249Z",
     "start_time": "2025-04-07T22:53:06.222591Z"
    }
   },
   "cell_type": "code",
   "source": "metrics, k_nn_df = degree_correlation_metrics()",
   "id": "eb96d85b978a6c27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating metrics for genre: blues\n",
      "calculating metrics for genre: classical\n",
      "calculating metrics for genre: country\n",
      "calculating metrics for genre: disco\n",
      "calculating metrics for genre: hiphop\n",
      "calculating metrics for genre: jazz\n",
      "calculating metrics for genre: metal\n",
      "calculating metrics for genre: pop\n",
      "calculating metrics for genre: reggae\n",
      "calculating metrics for genre: rock\n"
     ]
    }
   ],
   "execution_count": 450
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "seeing if genre has a significant impact on the value of $\\mu$:",
   "id": "3bb41881e44bcb91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:54:07.411688Z",
     "start_time": "2025-04-07T22:54:07.405060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k_nn_df['log_k'] = np.log10(k_nn_df['k'])\n",
    "k_nn_df['log_k_nn'] = np.log10(k_nn_df['k_nn'])"
   ],
   "id": "e9f753f07cc95697",
   "outputs": [],
   "execution_count": 451
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:54:07.532988Z",
     "start_time": "2025-04-07T22:54:07.433694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create linear regression model fitting k_nn against k, and has the genre as an interaction\n",
    "k_nn_model = ols(\"log_k_nn ~ log_k*genre\", data=k_nn_df).fit()\n",
    "k_nn_model.summary()\n",
    "#\n",
    "# k_nn_model_mult = ols(\"log_k_nn ~ log_k*genre\", data=k_nn_df).fit()\n",
    "# print(k_nn_model_mult.summary())"
   ],
   "id": "b7de1a5261f27245",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               log_k_nn   R-squared:                       0.546\n",
       "Model:                            OLS   Adj. R-squared:                  0.544\n",
       "Method:                 Least Squares   F-statistic:                     324.9\n",
       "Date:                Mon, 07 Apr 2025   Prob (F-statistic):               0.00\n",
       "Time:                        16:54:07   Log-Likelihood:                 131.27\n",
       "No. Observations:                5153   AIC:                            -222.5\n",
       "Df Residuals:                    5133   BIC:                            -91.60\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                    0.8146      0.025     33.093      0.000       0.766       0.863\n",
       "genre[T.classical]           0.1049      0.034      3.059      0.002       0.038       0.172\n",
       "genre[T.country]             0.0511      0.035      1.481      0.139      -0.017       0.119\n",
       "genre[T.disco]               0.0334      0.035      0.956      0.339      -0.035       0.102\n",
       "genre[T.hiphop]             -0.0660      0.034     -1.917      0.055      -0.134       0.001\n",
       "genre[T.jazz]                0.1684      0.036      4.661      0.000       0.098       0.239\n",
       "genre[T.metal]               0.0873      0.036      2.447      0.014       0.017       0.157\n",
       "genre[T.pop]                 0.1086      0.036      3.037      0.002       0.038       0.179\n",
       "genre[T.reggae]             -0.0691      0.035     -1.977      0.048      -0.138      -0.001\n",
       "genre[T.rock]                0.0017      0.033      0.052      0.958      -0.063       0.066\n",
       "log_k                        0.5205      0.020     26.216      0.000       0.482       0.559\n",
       "log_k:genre[T.classical]    -0.0727      0.028     -2.617      0.009      -0.127      -0.018\n",
       "log_k:genre[T.country]      -0.0393      0.028     -1.404      0.160      -0.094       0.016\n",
       "log_k:genre[T.disco]        -0.0255      0.028     -0.905      0.365      -0.081       0.030\n",
       "log_k:genre[T.hiphop]        0.0566      0.028      2.029      0.043       0.002       0.111\n",
       "log_k:genre[T.jazz]         -0.1283      0.029     -4.448      0.000      -0.185      -0.072\n",
       "log_k:genre[T.metal]        -0.0712      0.029     -2.487      0.013      -0.127      -0.015\n",
       "log_k:genre[T.pop]          -0.0827      0.029     -2.888      0.004      -0.139      -0.027\n",
       "log_k:genre[T.reggae]        0.0468      0.028      1.650      0.099      -0.009       0.102\n",
       "log_k:genre[T.rock]         -0.0096      0.027     -0.356      0.722      -0.063       0.043\n",
       "==============================================================================\n",
       "Omnibus:                      364.147   Durbin-Watson:                   1.640\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1794.649\n",
       "Skew:                          -0.109   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.883   Cond. No.                         50.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>log_k_nn</td>     <th>  R-squared:         </th> <td>   0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   324.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Apr 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:54:07</td>     <th>  Log-Likelihood:    </th> <td>  131.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5153</td>      <th>  AIC:               </th> <td>  -222.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5133</td>      <th>  BIC:               </th> <td>  -91.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>    0.8146</td> <td>    0.025</td> <td>   33.093</td> <td> 0.000</td> <td>    0.766</td> <td>    0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.classical]</th>       <td>    0.1049</td> <td>    0.034</td> <td>    3.059</td> <td> 0.002</td> <td>    0.038</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.country]</th>         <td>    0.0511</td> <td>    0.035</td> <td>    1.481</td> <td> 0.139</td> <td>   -0.017</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.disco]</th>           <td>    0.0334</td> <td>    0.035</td> <td>    0.956</td> <td> 0.339</td> <td>   -0.035</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.hiphop]</th>          <td>   -0.0660</td> <td>    0.034</td> <td>   -1.917</td> <td> 0.055</td> <td>   -0.134</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.jazz]</th>            <td>    0.1684</td> <td>    0.036</td> <td>    4.661</td> <td> 0.000</td> <td>    0.098</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.metal]</th>           <td>    0.0873</td> <td>    0.036</td> <td>    2.447</td> <td> 0.014</td> <td>    0.017</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.pop]</th>             <td>    0.1086</td> <td>    0.036</td> <td>    3.037</td> <td> 0.002</td> <td>    0.038</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.reggae]</th>          <td>   -0.0691</td> <td>    0.035</td> <td>   -1.977</td> <td> 0.048</td> <td>   -0.138</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>genre[T.rock]</th>            <td>    0.0017</td> <td>    0.033</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.063</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k</th>                    <td>    0.5205</td> <td>    0.020</td> <td>   26.216</td> <td> 0.000</td> <td>    0.482</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.classical]</th> <td>   -0.0727</td> <td>    0.028</td> <td>   -2.617</td> <td> 0.009</td> <td>   -0.127</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.country]</th>   <td>   -0.0393</td> <td>    0.028</td> <td>   -1.404</td> <td> 0.160</td> <td>   -0.094</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.disco]</th>     <td>   -0.0255</td> <td>    0.028</td> <td>   -0.905</td> <td> 0.365</td> <td>   -0.081</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.hiphop]</th>    <td>    0.0566</td> <td>    0.028</td> <td>    2.029</td> <td> 0.043</td> <td>    0.002</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.jazz]</th>      <td>   -0.1283</td> <td>    0.029</td> <td>   -4.448</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.metal]</th>     <td>   -0.0712</td> <td>    0.029</td> <td>   -2.487</td> <td> 0.013</td> <td>   -0.127</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.pop]</th>       <td>   -0.0827</td> <td>    0.029</td> <td>   -2.888</td> <td> 0.004</td> <td>   -0.139</td> <td>   -0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.reggae]</th>    <td>    0.0468</td> <td>    0.028</td> <td>    1.650</td> <td> 0.099</td> <td>   -0.009</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k:genre[T.rock]</th>      <td>   -0.0096</td> <td>    0.027</td> <td>   -0.356</td> <td> 0.722</td> <td>   -0.063</td> <td>    0.043</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>364.147</td> <th>  Durbin-Watson:     </th> <td>   1.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1794.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.109</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.883</td>  <th>  Cond. No.          </th> <td>    50.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}            &    log\\_k\\_nn    & \\textbf{  R-squared:         } &     0.546   \\\\\n\\textbf{Model:}                    &       OLS        & \\textbf{  Adj. R-squared:    } &     0.544   \\\\\n\\textbf{Method:}                   &  Least Squares   & \\textbf{  F-statistic:       } &     324.9   \\\\\n\\textbf{Date:}                     & Mon, 07 Apr 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n\\textbf{Time:}                     &     16:54:07     & \\textbf{  Log-Likelihood:    } &    131.27   \\\\\n\\textbf{No. Observations:}         &        5153      & \\textbf{  AIC:               } &    -222.5   \\\\\n\\textbf{Df Residuals:}             &        5133      & \\textbf{  BIC:               } &    -91.60   \\\\\n\\textbf{Df Model:}                 &          19      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}          &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Intercept}                 &       0.8146  &        0.025     &    33.093  &         0.000        &        0.766    &        0.863     \\\\\n\\textbf{genre[T.classical]}        &       0.1049  &        0.034     &     3.059  &         0.002        &        0.038    &        0.172     \\\\\n\\textbf{genre[T.country]}          &       0.0511  &        0.035     &     1.481  &         0.139        &       -0.017    &        0.119     \\\\\n\\textbf{genre[T.disco]}            &       0.0334  &        0.035     &     0.956  &         0.339        &       -0.035    &        0.102     \\\\\n\\textbf{genre[T.hiphop]}           &      -0.0660  &        0.034     &    -1.917  &         0.055        &       -0.134    &        0.001     \\\\\n\\textbf{genre[T.jazz]}             &       0.1684  &        0.036     &     4.661  &         0.000        &        0.098    &        0.239     \\\\\n\\textbf{genre[T.metal]}            &       0.0873  &        0.036     &     2.447  &         0.014        &        0.017    &        0.157     \\\\\n\\textbf{genre[T.pop]}              &       0.1086  &        0.036     &     3.037  &         0.002        &        0.038    &        0.179     \\\\\n\\textbf{genre[T.reggae]}           &      -0.0691  &        0.035     &    -1.977  &         0.048        &       -0.138    &       -0.001     \\\\\n\\textbf{genre[T.rock]}             &       0.0017  &        0.033     &     0.052  &         0.958        &       -0.063    &        0.066     \\\\\n\\textbf{log\\_k}                    &       0.5205  &        0.020     &    26.216  &         0.000        &        0.482    &        0.559     \\\\\n\\textbf{log\\_k:genre[T.classical]} &      -0.0727  &        0.028     &    -2.617  &         0.009        &       -0.127    &       -0.018     \\\\\n\\textbf{log\\_k:genre[T.country]}   &      -0.0393  &        0.028     &    -1.404  &         0.160        &       -0.094    &        0.016     \\\\\n\\textbf{log\\_k:genre[T.disco]}     &      -0.0255  &        0.028     &    -0.905  &         0.365        &       -0.081    &        0.030     \\\\\n\\textbf{log\\_k:genre[T.hiphop]}    &       0.0566  &        0.028     &     2.029  &         0.043        &        0.002    &        0.111     \\\\\n\\textbf{log\\_k:genre[T.jazz]}      &      -0.1283  &        0.029     &    -4.448  &         0.000        &       -0.185    &       -0.072     \\\\\n\\textbf{log\\_k:genre[T.metal]}     &      -0.0712  &        0.029     &    -2.487  &         0.013        &       -0.127    &       -0.015     \\\\\n\\textbf{log\\_k:genre[T.pop]}       &      -0.0827  &        0.029     &    -2.888  &         0.004        &       -0.139    &       -0.027     \\\\\n\\textbf{log\\_k:genre[T.reggae]}    &       0.0468  &        0.028     &     1.650  &         0.099        &       -0.009    &        0.102     \\\\\n\\textbf{log\\_k:genre[T.rock]}      &      -0.0096  &        0.027     &    -0.356  &         0.722        &       -0.063    &        0.043     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 364.147 & \\textbf{  Durbin-Watson:     } &    1.640  \\\\\n\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 1794.649  \\\\\n\\textbf{Skew:}          &  -0.109 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n\\textbf{Kurtosis:}      &   5.883 & \\textbf{  Cond. No.          } &     50.3  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 452
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:54:07.604987Z",
     "start_time": "2025-04-07T22:54:07.565683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a linear regression model for all genres combined where the only independent variable is the degree\n",
    "k_nn_model_no_interactions = ols(\"log_k_nn ~ log_k\", data=k_nn_df).fit()\n",
    "k_nn_model_no_interactions.summary()"
   ],
   "id": "9962708b430e7cc9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               log_k_nn   R-squared:                       0.538\n",
       "Model:                            OLS   Adj. R-squared:                  0.538\n",
       "Method:                 Least Squares   F-statistic:                     6001.\n",
       "Date:                Mon, 07 Apr 2025   Prob (F-statistic):               0.00\n",
       "Time:                        16:54:07   Log-Likelihood:                 86.833\n",
       "No. Observations:                5153   AIC:                            -169.7\n",
       "Df Residuals:                    5151   BIC:                            -156.6\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.8530      0.008    109.060      0.000       0.838       0.868\n",
       "log_k          0.4904      0.006     77.466      0.000       0.478       0.503\n",
       "==============================================================================\n",
       "Omnibus:                      345.899   Durbin-Watson:                   1.622\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1643.705\n",
       "Skew:                          -0.088   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.761   Cond. No.                         4.61\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ],
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>log_k_nn</td>     <th>  R-squared:         </th> <td>   0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6001.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Apr 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:54:07</td>     <th>  Log-Likelihood:    </th> <td>  86.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5153</td>      <th>  AIC:               </th> <td>  -169.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5151</td>      <th>  BIC:               </th> <td>  -156.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.8530</td> <td>    0.008</td> <td>  109.060</td> <td> 0.000</td> <td>    0.838</td> <td>    0.868</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>log_k</th>     <td>    0.4904</td> <td>    0.006</td> <td>   77.466</td> <td> 0.000</td> <td>    0.478</td> <td>    0.503</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>345.899</td> <th>  Durbin-Watson:     </th> <td>   1.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1643.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.088</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.761</td>  <th>  Cond. No.          </th> <td>    4.61</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &    log\\_k\\_nn    & \\textbf{  R-squared:         } &     0.538   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.538   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     6001.   \\\\\n\\textbf{Date:}             & Mon, 07 Apr 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n\\textbf{Time:}             &     16:54:07     & \\textbf{  Log-Likelihood:    } &    86.833   \\\\\n\\textbf{No. Observations:} &        5153      & \\textbf{  AIC:               } &    -169.7   \\\\\n\\textbf{Df Residuals:}     &        5151      & \\textbf{  BIC:               } &    -156.6   \\\\\n\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{Intercept} &       0.8530  &        0.008     &   109.060  &         0.000        &        0.838    &        0.868     \\\\\n\\textbf{log\\_k}    &       0.4904  &        0.006     &    77.466  &         0.000        &        0.478    &        0.503     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 345.899 & \\textbf{  Durbin-Watson:     } &    1.622  \\\\\n\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 1643.705  \\\\\n\\textbf{Skew:}          &  -0.088 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n\\textbf{Kurtosis:}      &   5.761 & \\textbf{  Cond. No.          } &     4.61  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 453
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:54:07.654281Z",
     "start_time": "2025-04-07T22:54:07.637440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# run a two-way ANOVA to see if the genre has a significant impact on the estimates of k_nn\n",
    "anova_lm(k_nn_model_no_interactions,  k_nn_model)"
   ],
   "id": "a728d6ab37f498ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   df_resid         ssr  df_diff   ss_diff         F        Pr(>F)\n",
       "0    5151.0  291.708560      0.0       NaN       NaN           NaN\n",
       "1    5133.0  286.720228     18.0  4.988332  4.961303  2.496797e-11"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_resid</th>\n",
       "      <th>ssr</th>\n",
       "      <th>df_diff</th>\n",
       "      <th>ss_diff</th>\n",
       "      <th>F</th>\n",
       "      <th>Pr(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5151.0</td>\n",
       "      <td>291.708560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5133.0</td>\n",
       "      <td>286.720228</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.988332</td>\n",
       "      <td>4.961303</td>\n",
       "      <td>2.496797e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 454
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
