{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to compute the centrality measures for each degree and put them back into their csv files\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing edge and node lists\n",
    "data_folder = \"networks\"  \n",
    "output_file = \"network_metrics.csv\"\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# Get all edge list files in the folder\n",
    "edge_files = sorted([f for f in os.listdir(data_folder) if \"edge_list\" in f and f.endswith(\".csv\")])\n",
    "# Get all node list files in the folder\n",
    "node_files = sorted([f for f in os.listdir(data_folder) if \"node_list\" in f and f.endswith(\".csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done blues\n",
      "Done classical\n",
      "Done country\n",
      "Done disco\n",
      "Done hiphop\n",
      "Done jazz\n",
      "Done metal\n",
      "Done null\n",
      "Done pop\n",
      "Done reggae\n",
      "Done rock\n"
     ]
    }
   ],
   "source": [
    "# Iterate through edge list files\n",
    "for edge_file in edge_files:\n",
    "    graph_id = edge_file.split(\"_\")[0].strip(\"'\")  # Extract identifier\n",
    "    node_file = f\"{graph_id}_node_list.csv\"  # Corresponding node file\n",
    "    \n",
    "    # Read node list (if it exists)\n",
    "    node_path = os.path.join(data_folder, node_file)\n",
    "    node_df = pd.read_csv(node_path)\n",
    "    nodes = node_df[\"Node\"].tolist() if os.path.exists(node_path) else []\n",
    "\n",
    "    # Read edge list\n",
    "    edge_path = os.path.join(data_folder, edge_file)\n",
    "    edges = pd.read_csv(edge_path)[[\"Node1\", \"Node2\"]].values.tolist()\n",
    "\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)  # Ensure all nodes are included\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Compute centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)  # Degree centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)  # Weighted betweenness\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G)  # Eigenvector centrality\n",
    "    closeness_centrality = nx.closeness_centrality(G)  # Closeness centrality\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    centrality_df = pd.DataFrame({\n",
    "        \"Node\": list(G.nodes),\n",
    "        \"degree_centrality\": [degree_centrality[n] for n in G.nodes],\n",
    "        \"betweenness_centrality\": [betweenness_centrality[n] for n in G.nodes],\n",
    "        \"eigenvector_centrality\": [eigenvector_centrality[n] for n in G.nodes],\n",
    "        \"closeness_centrality\": [closeness_centrality[n] for n in G.nodes],\n",
    "    })\n",
    "\n",
    "    # **Remove existing centrality columns if they exist**\n",
    "    centrality_columns = [\"degree_centrality\", \"betweenness_centrality\", \"eigenvector_centrality\", \"closeness_centrality\"]\n",
    "    node_df = node_df.drop(columns=[col for col in centrality_columns if col in node_df], errors=\"ignore\")\n",
    "\n",
    "    # Merge new centrality measures\n",
    "    node_df = node_df.merge(centrality_df, on=\"Node\", how=\"left\")\n",
    "\n",
    "    # Save updated node file\n",
    "    node_df.to_csv(node_path, index=False)\n",
    "    print(f\"Done {graph_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through node files\n",
    "for node_file in node_files:\n",
    "    graph_id = node_file.split(\"_\")[0].strip(\"'\")  # Extract identifier\n",
    "\n",
    "    # Read node file\n",
    "    node_path = os.path.join(data_folder, node_file)\n",
    "    node_df = pd.read_csv(node_path)\n",
    "\n",
    "    # Store the result\n",
    "    results.append({\n",
    "        \"Graph\": graph_id,\n",
    "        \"Degree Centrality\": node_df.loc[node_df[\"degree_centrality\"].idxmax()][\"Node\"],\n",
    "        \"Betweenness Centrality\": node_df.loc[node_df[\"betweenness_centrality\"].idxmax()][\"Node\"],\n",
    "        \"Eigenvector Centrality\": node_df.loc[node_df[\"eigenvector_centrality\"].idxmax()][\"Node\"],\n",
    "        \"Closeness Centrality\": node_df.loc[node_df[\"closeness_centrality\"].idxmax()][\"Node\"],\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "centrality_comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "centrality_comparison_df.to_csv(\"most_central_nodes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Graph</th>\n",
       "      <th>Degree Centrality</th>\n",
       "      <th>Betweenness Centrality</th>\n",
       "      <th>Eigenvector Centrality</th>\n",
       "      <th>Closeness Centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>313</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classical</td>\n",
       "      <td>398</td>\n",
       "      <td>11</td>\n",
       "      <td>398</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country</td>\n",
       "      <td>313</td>\n",
       "      <td>467</td>\n",
       "      <td>313</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disco</td>\n",
       "      <td>185</td>\n",
       "      <td>533</td>\n",
       "      <td>392</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiphop</td>\n",
       "      <td>392</td>\n",
       "      <td>361</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jazz</td>\n",
       "      <td>395</td>\n",
       "      <td>533</td>\n",
       "      <td>395</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>metal</td>\n",
       "      <td>313</td>\n",
       "      <td>102</td>\n",
       "      <td>313</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>null</td>\n",
       "      <td>313</td>\n",
       "      <td>108</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pop</td>\n",
       "      <td>395</td>\n",
       "      <td>221</td>\n",
       "      <td>395</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reggae</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>313</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rock</td>\n",
       "      <td>404</td>\n",
       "      <td>297</td>\n",
       "      <td>404</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Graph  Degree Centrality  Betweenness Centrality  \\\n",
       "0       blues                313                      11   \n",
       "1   classical                398                      11   \n",
       "2     country                313                     467   \n",
       "3       disco                185                     533   \n",
       "4      hiphop                392                     361   \n",
       "5        jazz                395                     533   \n",
       "6       metal                313                     102   \n",
       "7        null                313                     108   \n",
       "8         pop                395                     221   \n",
       "9      reggae                313                      11   \n",
       "10       rock                404                     297   \n",
       "\n",
       "    Eigenvector Centrality  Closeness Centrality  \n",
       "0                      313                   417  \n",
       "1                      398                   535  \n",
       "2                      313                    39  \n",
       "3                      392                   503  \n",
       "4                      392                   392  \n",
       "5                      395                   533  \n",
       "6                      313                   573  \n",
       "7                      313                   313  \n",
       "8                      395                     3  \n",
       "9                      313                   428  \n",
       "10                     404                   395  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regions to analyze\n",
    "regions = ['Vis', 'SomMot', 'DorsAttn_Post', 'DorsAttn_FEF', 'DorsAttn_PrCv',\n",
    " 'SalVentAttn_ParOper', 'SalVentAttn_TempOcc', 'SalVentAttn_FrOperIns',\n",
    " 'SalVentAttn_PFCl', 'SalVentAttn_Med', 'Limbic_OFC', 'Limbic_TempPole',\n",
    " 'Cont_Par', 'Cont_Temp', 'Cont_PFCd', 'Cont_OFC', 'Cont_PFCl', 'Cont_PFCv',\n",
    " 'Cont_pCun', 'Cont_Cing', 'Cont_PFCmp', 'Default_Temp', 'Default_Par',\n",
    " 'Default_PFC', 'Default_pCunPCC', 'Default_PHC', 'SalVentAttn_TempOccPar',\n",
    " 'SalVentAttn_PrC', 'Default_PFCv', 'Default_PFCdPFCm']\n",
    "\n",
    "networks = ['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont', 'Default']\n",
    "\n",
    "measures = [\"degree_centrality\", \"betweenness_centrality\", \"eigenvector_centrality\", \"closeness_centrality\"]\n",
    "\n",
    "for measure in measures:\n",
    "    # Iterate through node files\n",
    "    # List to store the results\n",
    "    graph_region_data = []\n",
    "    network_region_data = []\n",
    "    \n",
    "    for node_file in node_files:\n",
    "        graph_id = node_file.split(\"_\")[0]  # Extract graph identifier\n",
    "        node_path = os.path.join(data_folder, node_file)\n",
    "        node_df = pd.read_csv(node_path)\n",
    "\n",
    "        # Ensure the required columns exist\n",
    "        if \"Region\" in node_df.columns and measure in node_df.columns:\n",
    "            region_avg = {\"Graph_ID\": graph_id}\n",
    "            network_avg = {\"Graph_ID\": graph_id}\n",
    "\n",
    "            # Compute the average degree centrality for each region\n",
    "            for region in regions:\n",
    "                region_nodes = node_df[node_df[\"Region\"] == region]\n",
    "                avg_centrality = region_nodes[measure].mean() if not region_nodes.empty else None\n",
    "                region_avg[region] = avg_centrality\n",
    "\n",
    "            # Extract network names (everything before the first \"_\")\n",
    "            node_df[\"Network_Group\"] = node_df[\"Region\"].str.split(\"_\").str[0]\n",
    "\n",
    "            for network in networks:\n",
    "                network_nodes = node_df[node_df[\"Network_Group\"] == network]\n",
    "                avg_centrality = network_nodes[measure].mean() if not network_nodes.empty else None\n",
    "                network_avg[network] = avg_centrality\n",
    "\n",
    "            # Store the results\n",
    "            graph_region_data.append(region_avg)\n",
    "            network_region_data.append(network_avg)\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    graph_region_df = pd.DataFrame(graph_region_data)\n",
    "    graph_network_df = pd.DataFrame(network_region_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = f\"centrality/region_{measure}.csv\"\n",
    "    graph_region_df.to_csv(output_file, index=False)\n",
    "\n",
    "    output_file = f\"centrality/7Network_{measure}.csv\"\n",
    "    graph_network_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Significant difference found in SomMot (degree_centrality)! Running Tukey's HSD...\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      "  group1    group2  meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "    blues classical  -0.0012    1.0 -0.0149  0.0126  False\n",
      "    blues   country   0.0044 0.9919 -0.0094  0.0181  False\n",
      "    blues     disco   0.0088 0.5824  -0.005  0.0225  False\n",
      "    blues    hiphop   0.0009    1.0 -0.0129  0.0146  False\n",
      "    blues      jazz     0.01 0.3847 -0.0037  0.0237  False\n",
      "    blues     metal   0.0029 0.9997 -0.0109  0.0166  False\n",
      "    blues       pop   0.0039 0.9964 -0.0098  0.0177  False\n",
      "    blues    reggae  -0.0038 0.9971 -0.0175  0.0099  False\n",
      "    blues      rock  -0.0026 0.9999 -0.0164  0.0111  False\n",
      "classical   country   0.0055 0.9589 -0.0082  0.0193  False\n",
      "classical     disco   0.0099 0.3942 -0.0038  0.0237  False\n",
      "classical    hiphop    0.002    1.0 -0.0117  0.0158  False\n",
      "classical      jazz   0.0112 0.2297 -0.0026  0.0249  False\n",
      "classical     metal    0.004 0.9956 -0.0097  0.0178  False\n",
      "classical       pop   0.0051 0.9765 -0.0087  0.0188  False\n",
      "classical    reggae  -0.0026 0.9998 -0.0164  0.0111  False\n",
      "classical      rock  -0.0014    1.0 -0.0152  0.0123  False\n",
      "  country     disco   0.0044 0.9913 -0.0093  0.0182  False\n",
      "  country    hiphop  -0.0035 0.9985 -0.0172  0.0102  False\n",
      "  country      jazz   0.0056 0.9535 -0.0081  0.0194  False\n",
      "  country     metal  -0.0015    1.0 -0.0153  0.0122  False\n",
      "  country       pop  -0.0005    1.0 -0.0142  0.0133  False\n",
      "  country    reggae  -0.0082 0.6804 -0.0219  0.0056  False\n",
      "  country      rock   -0.007 0.8433 -0.0207  0.0068  False\n",
      "    disco    hiphop  -0.0079 0.7186 -0.0217  0.0058  False\n",
      "    disco      jazz   0.0012    1.0 -0.0125   0.015  False\n",
      "    disco     metal  -0.0059 0.9373 -0.0197  0.0078  False\n",
      "    disco       pop  -0.0049 0.9825 -0.0186  0.0089  False\n",
      "    disco    reggae  -0.0126 0.1065 -0.0263  0.0012  False\n",
      "    disco      rock  -0.0114  0.206 -0.0251  0.0024  False\n",
      "   hiphop      jazz   0.0091 0.5208 -0.0046  0.0229  False\n",
      "   hiphop     metal    0.002    1.0 -0.0117  0.0157  False\n",
      "   hiphop       pop   0.0031 0.9995 -0.0107  0.0168  False\n",
      "   hiphop    reggae  -0.0047  0.987 -0.0184  0.0091  False\n",
      "   hiphop      rock  -0.0035 0.9986 -0.0172  0.0103  False\n",
      "     jazz     metal  -0.0072 0.8231 -0.0209  0.0066  False\n",
      "     jazz       pop  -0.0061 0.9257 -0.0198  0.0077  False\n",
      "     jazz    reggae  -0.0138 0.0479 -0.0275 -0.0001   True\n",
      "     jazz      rock  -0.0126 0.1035 -0.0264  0.0011  False\n",
      "    metal       pop   0.0011    1.0 -0.0127  0.0148  False\n",
      "    metal    reggae  -0.0067  0.878 -0.0204  0.0071  False\n",
      "    metal      rock  -0.0055 0.9617 -0.0192  0.0083  False\n",
      "      pop    reggae  -0.0077 0.7484 -0.0215   0.006  False\n",
      "      pop      rock  -0.0065 0.8899 -0.0203  0.0072  False\n",
      "   reggae      rock   0.0012    1.0 -0.0126  0.0149  False\n",
      "----------------------------------------------------------\n",
      "\n",
      "Significant difference found in SomMot (closeness_centrality)! Running Tukey's HSD...\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      "  group1    group2  meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "    blues classical   -0.015 0.9028 -0.0474  0.0173  False\n",
      "    blues   country   0.0103 0.9919 -0.0221  0.0426  False\n",
      "    blues     disco   0.0216 0.5158 -0.0107  0.0539  False\n",
      "    blues    hiphop  -0.0064 0.9998 -0.0387   0.026  False\n",
      "    blues      jazz    0.026 0.2461 -0.0064  0.0583  False\n",
      "    blues     metal   0.0347 0.0241  0.0024  0.0671   True\n",
      "    blues       pop  -0.0028    1.0 -0.0351  0.0296  False\n",
      "    blues    reggae  -0.0034    1.0 -0.0358  0.0289  False\n",
      "    blues      rock  -0.0057 0.9999  -0.038  0.0266  False\n",
      "classical   country   0.0253 0.2811 -0.0071  0.0576  False\n",
      "classical     disco   0.0366 0.0127  0.0043   0.069   True\n",
      "classical    hiphop   0.0087 0.9978 -0.0237   0.041  False\n",
      "classical      jazz    0.041 0.0025  0.0086  0.0733   True\n",
      "classical     metal   0.0497 0.0001  0.0174  0.0821   True\n",
      "classical       pop   0.0122 0.9724 -0.0201  0.0446  False\n",
      "classical    reggae   0.0116 0.9807 -0.0207   0.044  False\n",
      "classical      rock   0.0093  0.996  -0.023  0.0417  False\n",
      "  country     disco   0.0113 0.9837  -0.021  0.0437  False\n",
      "  country    hiphop  -0.0166 0.8332  -0.049  0.0157  False\n",
      "  country      jazz   0.0157 0.8765 -0.0166   0.048  False\n",
      "  country     metal   0.0244 0.3291 -0.0079  0.0568  False\n",
      "  country       pop   -0.013 0.9583 -0.0454  0.0193  False\n",
      "  country    reggae  -0.0137  0.944  -0.046  0.0187  False\n",
      "  country      rock   -0.016 0.8649 -0.0483  0.0164  False\n",
      "    disco    hiphop   -0.028 0.1587 -0.0603  0.0044  False\n",
      "    disco      jazz   0.0044    1.0  -0.028  0.0367  False\n",
      "    disco     metal   0.0131 0.9569 -0.0192  0.0455  False\n",
      "    disco       pop  -0.0244 0.3331 -0.0567   0.008  False\n",
      "    disco    reggae   -0.025 0.2964 -0.0574  0.0073  False\n",
      "    disco      rock  -0.0273  0.185 -0.0596   0.005  False\n",
      "   hiphop      jazz   0.0323 0.0502    -0.0  0.0647  False\n",
      "   hiphop     metal   0.0411 0.0024  0.0087  0.0734   True\n",
      "   hiphop       pop   0.0036    1.0 -0.0288  0.0359  False\n",
      "   hiphop    reggae    0.003    1.0 -0.0294  0.0353  False\n",
      "   hiphop      rock   0.0007    1.0 -0.0317   0.033  False\n",
      "     jazz     metal   0.0088 0.9976 -0.0236  0.0411  False\n",
      "     jazz       pop  -0.0287 0.1319 -0.0611  0.0036  False\n",
      "     jazz    reggae  -0.0294 0.1127 -0.0617   0.003  False\n",
      "     jazz      rock  -0.0317  0.061  -0.064  0.0007  False\n",
      "    metal       pop  -0.0375 0.0094 -0.0698 -0.0051   True\n",
      "    metal    reggae  -0.0381 0.0075 -0.0705 -0.0058   True\n",
      "    metal      rock  -0.0404 0.0032 -0.0728 -0.0081   True\n",
      "      pop    reggae  -0.0006    1.0  -0.033  0.0317  False\n",
      "      pop      rock  -0.0029    1.0 -0.0353  0.0294  False\n",
      "   reggae      rock  -0.0023    1.0 -0.0346  0.0301  False\n",
      "----------------------------------------------------------\n",
      "\n",
      "Significant difference found in Limbic (closeness_centrality)! Running Tukey's HSD...\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      "  group1    group2  meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "    blues classical   0.0374 0.8092 -0.0336  0.1084  False\n",
      "    blues   country   0.0289 0.9541 -0.0421  0.0999  False\n",
      "    blues     disco    0.042 0.6806  -0.029   0.113  False\n",
      "    blues    hiphop   0.0269 0.9712 -0.0441  0.0979  False\n",
      "    blues      jazz    0.064 0.1179  -0.007   0.135  False\n",
      "    blues     metal   0.0523 0.3625 -0.0187  0.1233  False\n",
      "    blues       pop   0.0526 0.3551 -0.0184  0.1236  False\n",
      "    blues    reggae  -0.0073    1.0 -0.0783  0.0637  False\n",
      "    blues      rock   0.0493 0.4519 -0.0217  0.1203  False\n",
      "classical   country  -0.0084    1.0 -0.0794  0.0625  False\n",
      "classical     disco   0.0046    1.0 -0.0663  0.0756  False\n",
      "classical    hiphop  -0.0105    1.0 -0.0814  0.0605  False\n",
      "classical      jazz   0.0266  0.973 -0.0443  0.0976  False\n",
      "classical     metal    0.015 0.9997  -0.056  0.0859  False\n",
      "classical       pop   0.0152 0.9996 -0.0558  0.0862  False\n",
      "classical    reggae  -0.0447 0.5977 -0.1157  0.0263  False\n",
      "classical      rock   0.0119 0.9999 -0.0591  0.0829  False\n",
      "  country     disco   0.0131 0.9999 -0.0579  0.0841  False\n",
      "  country    hiphop   -0.002    1.0  -0.073   0.069  False\n",
      "  country      jazz   0.0351 0.8608 -0.0359  0.1061  False\n",
      "  country     metal   0.0234  0.989 -0.0476  0.0944  False\n",
      "  country       pop   0.0237 0.9881 -0.0473  0.0946  False\n",
      "  country    reggae  -0.0362 0.8357 -0.1072  0.0347  False\n",
      "  country      rock   0.0204  0.996 -0.0506  0.0914  False\n",
      "    disco    hiphop  -0.0151 0.9996 -0.0861  0.0559  False\n",
      "    disco      jazz    0.022  0.993  -0.049   0.093  False\n",
      "    disco     metal   0.0103    1.0 -0.0607  0.0813  False\n",
      "    disco       pop   0.0106    1.0 -0.0604  0.0816  False\n",
      "    disco    reggae  -0.0493  0.451 -0.1203  0.0217  False\n",
      "    disco      rock   0.0073    1.0 -0.0637  0.0783  False\n",
      "   hiphop      jazz   0.0371 0.8156 -0.0339  0.1081  False\n",
      "   hiphop     metal   0.0254 0.9804 -0.0456  0.0964  False\n",
      "   hiphop       pop   0.0257  0.979 -0.0453  0.0967  False\n",
      "   hiphop    reggae  -0.0342 0.8779 -0.1052  0.0368  False\n",
      "   hiphop      rock   0.0224  0.992 -0.0486  0.0934  False\n",
      "     jazz     metal  -0.0117    1.0 -0.0827  0.0593  False\n",
      "     jazz       pop  -0.0114    1.0 -0.0824  0.0596  False\n",
      "     jazz    reggae  -0.0713 0.0478 -0.1423 -0.0003   True\n",
      "     jazz      rock  -0.0147 0.9997 -0.0857  0.0563  False\n",
      "    metal       pop   0.0003    1.0 -0.0707  0.0712  False\n",
      "    metal    reggae  -0.0596 0.1884 -0.1306  0.0113  False\n",
      "    metal      rock   -0.003    1.0  -0.074   0.068  False\n",
      "      pop    reggae  -0.0599 0.1835 -0.1309  0.0111  False\n",
      "      pop      rock  -0.0033    1.0 -0.0743  0.0677  False\n",
      "   reggae      rock   0.0566 0.2518 -0.0144  0.1276  False\n",
      "----------------------------------------------------------\n",
      "\n",
      "Significant difference found in Default (closeness_centrality)! Running Tukey's HSD...\n",
      "\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      "  group1    group2  meandiff p-adj   lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "    blues classical    0.009 0.9984 -0.0263 0.0444  False\n",
      "    blues   country   0.0297 0.1911 -0.0057  0.065  False\n",
      "    blues     disco   0.0249 0.4332 -0.0104 0.0602  False\n",
      "    blues    hiphop     -0.0    1.0 -0.0354 0.0353  False\n",
      "    blues      jazz   0.0314 0.1321 -0.0039 0.0667  False\n",
      "    blues     metal   0.0378 0.0246  0.0025 0.0732   True\n",
      "    blues       pop   0.0085  0.999 -0.0268 0.0439  False\n",
      "    blues    reggae   0.0209  0.688 -0.0145 0.0562  False\n",
      "    blues      rock   0.0251 0.4196 -0.0102 0.0605  False\n",
      "classical   country   0.0206 0.7029 -0.0147 0.0559  False\n",
      "classical     disco   0.0159 0.9197 -0.0194 0.0512  False\n",
      "classical    hiphop  -0.0091 0.9984 -0.0444 0.0262  False\n",
      "classical      jazz   0.0224 0.5954  -0.013 0.0577  False\n",
      "classical     metal   0.0288 0.2257 -0.0065 0.0641  False\n",
      "classical       pop  -0.0005    1.0 -0.0358 0.0348  False\n",
      "classical    reggae   0.0118 0.9881 -0.0235 0.0472  False\n",
      "classical      rock   0.0161 0.9129 -0.0192 0.0514  False\n",
      "  country     disco  -0.0047    1.0 -0.0401 0.0306  False\n",
      "  country    hiphop  -0.0297 0.1893  -0.065 0.0056  False\n",
      "  country      jazz   0.0017    1.0 -0.0336 0.0371  False\n",
      "  country     metal   0.0082 0.9993 -0.0271 0.0435  False\n",
      "  country       pop  -0.0211 0.6733 -0.0564 0.0142  False\n",
      "  country    reggae  -0.0088 0.9987 -0.0441 0.0265  False\n",
      "  country      rock  -0.0045    1.0 -0.0398 0.0308  False\n",
      "    disco    hiphop   -0.025 0.4302 -0.0603 0.0104  False\n",
      "    disco      jazz   0.0065 0.9999 -0.0288 0.0418  False\n",
      "    disco     metal   0.0129  0.978 -0.0224 0.0483  False\n",
      "    disco       pop  -0.0164 0.9044 -0.0517  0.019  False\n",
      "    disco    reggae   -0.004    1.0 -0.0394 0.0313  False\n",
      "    disco      rock   0.0002    1.0 -0.0351 0.0355  False\n",
      "   hiphop      jazz   0.0314 0.1307 -0.0039 0.0668  False\n",
      "   hiphop     metal   0.0379 0.0242  0.0026 0.0732   True\n",
      "   hiphop       pop   0.0086 0.9989 -0.0267 0.0439  False\n",
      "   hiphop    reggae   0.0209 0.6851 -0.0144 0.0562  False\n",
      "   hiphop      rock   0.0252 0.4167 -0.0101 0.0605  False\n",
      "     jazz     metal   0.0065 0.9999 -0.0289 0.0418  False\n",
      "     jazz       pop  -0.0228 0.5641 -0.0582 0.0125  False\n",
      "     jazz    reggae  -0.0105  0.995 -0.0458 0.0248  False\n",
      "     jazz      rock  -0.0063 0.9999 -0.0416 0.0291  False\n",
      "    metal       pop  -0.0293 0.2051 -0.0646  0.006  False\n",
      "    metal    reggae   -0.017 0.8829 -0.0523 0.0183  False\n",
      "    metal      rock  -0.0127 0.9804  -0.048 0.0226  False\n",
      "      pop    reggae   0.0123 0.9842  -0.023 0.0476  False\n",
      "      pop      rock   0.0166 0.8969 -0.0187 0.0519  False\n",
      "   reggae      rock   0.0043    1.0 -0.0311 0.0396  False\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Define the regions to analyze\n",
    "regions = ['Vis', 'SomMot', 'DorsAttn_Post', 'DorsAttn_FEF', 'DorsAttn_PrCv',\n",
    " 'SalVentAttn_ParOper', 'SalVentAttn_TempOcc', 'SalVentAttn_FrOperIns',\n",
    " 'SalVentAttn_PFCl', 'SalVentAttn_Med', 'Limbic_OFC', 'Limbic_TempPole',\n",
    " 'Cont_Par', 'Cont_Temp', 'Cont_PFCd', 'Cont_OFC', 'Cont_PFCl', 'Cont_PFCv',\n",
    " 'Cont_pCun', 'Cont_Cing', 'Cont_PFCmp', 'Default_Temp', 'Default_Par',\n",
    " 'Default_PFC', 'Default_pCunPCC', 'Default_PHC', 'SalVentAttn_TempOccPar',\n",
    " 'SalVentAttn_PrC', 'Default_PFCv', 'Default_PFCdPFCm']\n",
    "\n",
    "networks = ['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont', 'Default']\n",
    "measures = [\"degree_centrality\", \"betweenness_centrality\", \"eigenvector_centrality\", \"closeness_centrality\"]\n",
    "\n",
    "# Store statistical results\n",
    "stats_results = []\n",
    "\n",
    "for measure in measures:\n",
    "    network_data = []  # Store data for all graphs (all genres)\n",
    "\n",
    "    for node_file in node_files:\n",
    "        if node_file == \"null_node_list.csv\":\n",
    "            continue\n",
    "        graph_id = node_file.split(\"_\")[0]  # Extract genre identifier\n",
    "        node_path = os.path.join(data_folder, node_file)\n",
    "        node_df = pd.read_csv(node_path)\n",
    "\n",
    "        if \"Region\" in node_df.columns and measure in node_df.columns:\n",
    "            node_df[\"Network_Group\"] = node_df[\"Region\"].str.split(\"_\").str[0]\n",
    "\n",
    "            for network in networks:\n",
    "                network_nodes = node_df[node_df[\"Network_Group\"] == network]\n",
    "\n",
    "                if len(network_nodes) > 1:  # Ensure we have enough data points\n",
    "                    for _, row in network_nodes.iterrows():\n",
    "                        network_data.append({\n",
    "                            \"Graph_ID\": graph_id,\n",
    "                            \"Network\": network,\n",
    "                            \"Centrality\": row[measure]\n",
    "                        })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    network_df = pd.DataFrame(network_data)\n",
    "\n",
    "    # Perform ANOVA for each network\n",
    "    for network in networks:\n",
    "        network_subset = network_df[network_df[\"Network\"] == network]\n",
    "\n",
    "        if network_subset.empty:\n",
    "            continue  # Skip if no data\n",
    "\n",
    "        groups = [network_subset[network_subset[\"Graph_ID\"] == g][\"Centrality\"].values \n",
    "                  for g in network_subset[\"Graph_ID\"].unique()]\n",
    "\n",
    "        if len(groups) > 1 and all(len(g) > 1 for g in groups):  # Ensure valid data for ANOVA\n",
    "            anova_p = stats.f_oneway(*groups).pvalue\n",
    "        else:\n",
    "            anova_p = float('nan')  # Not enough data\n",
    "\n",
    "        stats_results.append({\"Network\": network, \"Measure\": measure, \"P-Value\": anova_p})\n",
    "\n",
    "        # If significant, run Tukey's HSD\n",
    "        if anova_p < 0.05:\n",
    "            print(f\"\\nSignificant difference found in {network} ({measure})! Running Tukey's HSD...\\n\")\n",
    "            tukey = pairwise_tukeyhsd(network_subset[\"Centrality\"], network_subset[\"Graph_ID\"], alpha=0.05)\n",
    "            print(tukey)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "stats_df = pd.DataFrame(stats_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
