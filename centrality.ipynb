{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to compute the centrality measures for each degree and put them back into their csv files\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing edge and node lists\n",
    "data_folder = \"networks\"  \n",
    "output_file = \"network_metrics.csv\"\n",
    "\n",
    "# Initialize results list\n",
    "results = []\n",
    "\n",
    "# Get all edge list files in the folder\n",
    "edge_files = sorted([f for f in os.listdir(data_folder) if \"edge_list\" in f and f.endswith(\".csv\")])\n",
    "# Get all node list files in the folder\n",
    "node_files = sorted([f for f in os.listdir(data_folder) if \"node_list\" in f and f.endswith(\".csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done blues\n",
      "Done classical\n",
      "Done country\n",
      "Done disco\n",
      "Done hiphop\n",
      "Done jazz\n",
      "Done metal\n",
      "Done null\n",
      "Done pop\n",
      "Done reggae\n",
      "Done rock\n"
     ]
    }
   ],
   "source": [
    "# Iterate through edge list files\n",
    "for edge_file in edge_files:\n",
    "    graph_id = edge_file.split(\"_\")[0].strip(\"'\")  # Extract identifier\n",
    "    node_file = f\"{graph_id}_node_list.csv\"  # Corresponding node file\n",
    "    \n",
    "    # Read node list (if it exists)\n",
    "    node_path = os.path.join(data_folder, node_file)\n",
    "    node_df = pd.read_csv(node_path)\n",
    "    nodes = node_df[\"Node\"].tolist() if os.path.exists(node_path) else []\n",
    "\n",
    "    # Read edge list\n",
    "    edge_path = os.path.join(data_folder, edge_file)\n",
    "    edges = pd.read_csv(edge_path)[[\"Node1\", \"Node2\"]].values.tolist()\n",
    "\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(nodes)  # Ensure all nodes are included\n",
    "    G.add_edges_from(edges)\n",
    "\n",
    "    # Compute centrality measures\n",
    "    degree_centrality = nx.degree_centrality(G)  # Degree centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)  # Weighted betweenness\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G)  # Eigenvector centrality\n",
    "    closeness_centrality = nx.closeness_centrality(G)  # Closeness centrality\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    centrality_df = pd.DataFrame({\n",
    "        \"Node\": list(G.nodes),\n",
    "        \"degree_centrality\": [degree_centrality[n] for n in G.nodes],\n",
    "        \"betweenness_centrality\": [betweenness_centrality[n] for n in G.nodes],\n",
    "        \"eigenvector_centrality\": [eigenvector_centrality[n] for n in G.nodes],\n",
    "        \"closeness_centrality\": [closeness_centrality[n] for n in G.nodes],\n",
    "    })\n",
    "\n",
    "    # **Remove existing centrality columns if they exist**\n",
    "    centrality_columns = [\"degree_centrality\", \"betweenness_centrality\", \"eigenvector_centrality\", \"closeness_centrality\"]\n",
    "    node_df = node_df.drop(columns=[col for col in centrality_columns if col in node_df], errors=\"ignore\")\n",
    "\n",
    "    # Merge new centrality measures\n",
    "    node_df = node_df.merge(centrality_df, on=\"Node\", how=\"left\")\n",
    "\n",
    "    # Save updated node file\n",
    "    node_df.to_csv(node_path, index=False)\n",
    "    print(f\"Done {graph_id}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through node files\n",
    "for node_file in node_files:\n",
    "    graph_id = node_file.split(\"_\")[0].strip(\"'\")  # Extract identifier\n",
    "\n",
    "    # Read node file\n",
    "    node_path = os.path.join(data_folder, node_file)\n",
    "    node_df = pd.read_csv(node_path)\n",
    "\n",
    "    # Store the result\n",
    "    results.append({\n",
    "        \"Graph\": graph_id,\n",
    "        \"Degree Centrality\": node_df.loc[node_df[\"degree_centrality\"].idxmax()][\"Node\"],\n",
    "        \"Betweenness Centrality\": node_df.loc[node_df[\"betweenness_centrality\"].idxmax()][\"Node\"],\n",
    "        \"Eigenvector Centrality\": node_df.loc[node_df[\"eigenvector_centrality\"].idxmax()][\"Node\"],\n",
    "        \"Closeness Centrality\": node_df.loc[node_df[\"closeness_centrality\"].idxmax()][\"Node\"],\n",
    "    })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "centrality_comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "centrality_comparison_df.to_csv(\"most_central_nodes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Graph</th>\n",
       "      <th>Degree Centrality</th>\n",
       "      <th>Betweenness Centrality</th>\n",
       "      <th>Eigenvector Centrality</th>\n",
       "      <th>Closeness Centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>313</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classical</td>\n",
       "      <td>398</td>\n",
       "      <td>11</td>\n",
       "      <td>398</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country</td>\n",
       "      <td>313</td>\n",
       "      <td>467</td>\n",
       "      <td>313</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disco</td>\n",
       "      <td>185</td>\n",
       "      <td>533</td>\n",
       "      <td>392</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiphop</td>\n",
       "      <td>392</td>\n",
       "      <td>361</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jazz</td>\n",
       "      <td>395</td>\n",
       "      <td>533</td>\n",
       "      <td>395</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>metal</td>\n",
       "      <td>313</td>\n",
       "      <td>102</td>\n",
       "      <td>313</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>null</td>\n",
       "      <td>313</td>\n",
       "      <td>108</td>\n",
       "      <td>313</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pop</td>\n",
       "      <td>395</td>\n",
       "      <td>221</td>\n",
       "      <td>395</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>reggae</td>\n",
       "      <td>313</td>\n",
       "      <td>11</td>\n",
       "      <td>313</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rock</td>\n",
       "      <td>404</td>\n",
       "      <td>297</td>\n",
       "      <td>404</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Graph  Degree Centrality  Betweenness Centrality  \\\n",
       "0       blues                313                      11   \n",
       "1   classical                398                      11   \n",
       "2     country                313                     467   \n",
       "3       disco                185                     533   \n",
       "4      hiphop                392                     361   \n",
       "5        jazz                395                     533   \n",
       "6       metal                313                     102   \n",
       "7        null                313                     108   \n",
       "8         pop                395                     221   \n",
       "9      reggae                313                      11   \n",
       "10       rock                404                     297   \n",
       "\n",
       "    Eigenvector Centrality  Closeness Centrality  \n",
       "0                      313                   417  \n",
       "1                      398                   535  \n",
       "2                      313                    39  \n",
       "3                      392                   503  \n",
       "4                      392                   392  \n",
       "5                      395                   533  \n",
       "6                      313                   573  \n",
       "7                      313                   313  \n",
       "8                      395                     3  \n",
       "9                      313                   428  \n",
       "10                     404                   395  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centrality_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regions to analyze\n",
    "regions = ['Vis', 'SomMot', 'DorsAttn_Post', 'DorsAttn_FEF', 'DorsAttn_PrCv',\n",
    " 'SalVentAttn_ParOper', 'SalVentAttn_TempOcc', 'SalVentAttn_FrOperIns',\n",
    " 'SalVentAttn_PFCl', 'SalVentAttn_Med', 'Limbic_OFC', 'Limbic_TempPole',\n",
    " 'Cont_Par', 'Cont_Temp', 'Cont_PFCd', 'Cont_OFC', 'Cont_PFCl', 'Cont_PFCv',\n",
    " 'Cont_pCun', 'Cont_Cing', 'Cont_PFCmp', 'Default_Temp', 'Default_Par',\n",
    " 'Default_PFC', 'Default_pCunPCC', 'Default_PHC', 'SalVentAttn_TempOccPar',\n",
    " 'SalVentAttn_PrC', 'Default_PFCv', 'Default_PFCdPFCm']\n",
    "\n",
    "networks = ['Vis', 'SomMot', 'DorsAttn', 'SalVentAttn', 'Limbic', 'Cont', 'Default']\n",
    "\n",
    "measures = [\"degree_centrality\", \"betweenness_centrality\", \"eigenvector_centrality\", \"closeness_centrality\"]\n",
    "\n",
    "for measure in measures:\n",
    "    # Iterate through node files\n",
    "    # List to store the results\n",
    "    graph_region_data = []\n",
    "    network_region_data = []\n",
    "    \n",
    "    for node_file in node_files:\n",
    "        graph_id = node_file.split(\"_\")[0]  # Extract graph identifier\n",
    "        node_path = os.path.join(data_folder, node_file)\n",
    "        node_df = pd.read_csv(node_path)\n",
    "\n",
    "        # Ensure the required columns exist\n",
    "        if \"Region\" in node_df.columns and measure in node_df.columns:\n",
    "            region_avg = {\"Graph_ID\": graph_id}\n",
    "            network_avg = {\"Graph_ID\": graph_id}\n",
    "\n",
    "            # Compute the average degree centrality for each region\n",
    "            for region in regions:\n",
    "                region_nodes = node_df[node_df[\"Region\"] == region]\n",
    "                avg_centrality = region_nodes[measure].mean() if not region_nodes.empty else None\n",
    "                region_avg[region] = avg_centrality\n",
    "\n",
    "            # Extract network names (everything before the first \"_\")\n",
    "            node_df[\"Network_Group\"] = node_df[\"Region\"].str.split(\"_\").str[0]\n",
    "\n",
    "            for network in networks:\n",
    "                network_nodes = node_df[node_df[\"Network_Group\"] == network]\n",
    "                avg_centrality = network_nodes[measure].mean() if not network_nodes.empty else None\n",
    "                network_avg[network] = avg_centrality\n",
    "\n",
    "            # Store the results\n",
    "            graph_region_data.append(region_avg)\n",
    "            network_region_data.append(network_avg)\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    graph_region_df = pd.DataFrame(graph_region_data)\n",
    "    graph_network_df = pd.DataFrame(network_region_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    output_file = f\"centrality/region_{measure}.csv\"\n",
    "    graph_region_df.to_csv(output_file, index=False)\n",
    "\n",
    "    output_file = f\"centrality/7Network_{measure}.csv\"\n",
    "    graph_network_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
